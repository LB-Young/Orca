url: /link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS5FLi4EgWb-ac5xX9FJB7cPIVPsd-072FlqXa8Fplpd9RDt0mcq4xPpUufM75GVtgOpJv4QmgItfmYvQKnK4k436-0mZTZKs7lACkdGVCYIG0TOkmvlSayI19Cul-EidOjYfi4AYBlrEGevhUh78oWh5KZs10iaN2Lk4p0zgV6-0V-yqKdrTLaTAAdr3lhuNbsfkpe5ydl5hyjG_EmviP3Dy08OLTBhW0A..&type=2&query=gemini 2.0&token=E0154816F18175B88385AB8F75C855C283618CC5675A95BC
title:  
time: 6小时前
abstract: 相比前代模型,
user_id: 硅星人Pro
content: 作者｜Jessica
邮箱｜JessicaZhang@pingwest.com
OpenAI发布会进入第5天，带来了ChatGPT与Apple设备的集成升级。用户无需ChatGPT账号就能在设置中启用Apple Intelligence扩展，体验Siri的复杂任务转交、内容创作、iPhone 16视觉智能模式，以及macOS上的快捷调用功能。
演示内容也很简单：用户对Siri说“让ChatGPT…”后，请求即被ChatGPT接管；长按iPhone 16侧边摄像头控制键打开相机，点击“ask”调用ChatGPT分析拍摄内容；在macOS双击Command键激活ChatGPT，快速分析提炼长PDF文档信息。
直播仅持续12分钟，由于大多早已在Apple的demo中见过，整体看来平平无奇。
而今天真正的高光时刻，来自Google。
当地时间早晨，Sundar Pichai、Demis Hassabis和Koray Kavukcuoglu联合发文，重磅官宣Google迄今最强大、专门适配全新“代理时代”的下一代模型Gemini 2.0。并正式发布该系列首个版本：Gemini 2.0 Flash实验版。
1
性能超1.5 Pro，多模态重大突破，原生工具集成
Gemini 2.0 Flash以低延迟和增强性能为核心，代表了Google在AI模型开发领域的最高水平。
相比前代模型，Gemini 2.0 Flash 在保持快速响应的基础上性能显著提升。在MMLU、编程、数学、推理等关键基准测试中不仅超越了1.5 Pro的表现，速度更提升了一倍。
多模态方面，2.0 Flash实现了跨越式进展：除支持图像、视频、音频等多模态输入外，还新增了多模态输出功能，包括原生的图文混合生成和多语言文本转语音。
同时，模型还能原生调用Google搜索、执行程序代码，并支持用户自定义的第三方工具接入。
开发者支持：多模态实时 API
为帮助开发者构建更丰富的动态交互应用，Google同步推出了一款新的多模态实时API，支持实时音视频流输入和多工具组合调用。
目前，开发者可通过Google AI Studio和Vertex AI平台使用2.0 Flash实验版的多模态输入和文本输出功能。而文本转语音和原生图像生成功能暂时仅向早期合作伙伴开放，预计将在明年1月实现更大范围的功能开放和模型版本更新。
全球用户可用，新增研究利器Deep Research
在用户端，2.0 Flash实验版已整合至Gemini聊天助手中，全球用户可以通过桌面和移动网页版的模型下拉菜单访问，移动应用集成也将于不久后推出。
Google 正在搜索中的 AI 概览功能中测试 Gemini 2.0 的高级推理能力，以帮助解答更复杂和多步骤的问题，并计划在明年初扩展到更多Google产品中。
特别值得一提的是，针对 Advanced 付费用户，Google 今天还推出一项全新的 Deep Research功能。
它专为复杂在线研究设计，能在用户提出问题后基于Gemini 1.5 Pro自动创建多步骤研究计划，收集和分析全网相关信息，并根据反馈不断优化，最终生成一份包含深入信息和准确来源的综合报告。大幅简化繁琐耗时的研究过程，堪称科研工作者福音，PhD狂喜。
00:49
1
为“Agent 元年”打造的AI模型
Gemini 2.0系列模型定位鲜明，直接就是“AI model for the agentic era” 。
Pichai表示，过去一年Google一直专注于开发具备更强代理能力的模型，这类模型能深入理解用户所处环境，具备多步预判思维，并在监督下执行相应操作。结合此前发布的 Genie 2，Google 的空间智能和世界模型愿景已显露无疑。
Hassabis更直言 2025 年将是“Agent 元年”，称Gemini 2.0 Flash的原生用户界面交互、多模态推理、长上下文理解、复杂指令执行与规划、函数调用组合以及原生工具使用等，将使其成为未来agent式工作的核心支持模型，进一步接近打造“通用助手”的愿景。
本次发布中，Google 展示了一系列基于 2.0 Flash 新能力的原型项目进展，包括：
Project Astra：现实世界中的通用智能助手
04:32
今年I/O大会上，Google首次展示了具备多模态理解能力、支持即时语音交互的Project Astra。得益于Gemini 2.0的加持和Android测试者的反馈，最新版本的Astra实现了以下关键升级：
• 对话能力全面提升：支持多语言及混合语言交流，能更准确理解不同口音和生僻词汇。
• 工具调用升级：原生集成Google搜索、Lens和地图功能，显著提升了在日常生活中的实用性。
• 记忆增强：能在对话中保持更丰富的上下文信息，支持长达10分钟的会话记忆，为用户带来更加个性化的交互体验。
• 延迟优化：通过新一代流媒体和音频理解技术，将响应速度提升至接近人类对话水平。
Project Mariner：浏览器中的复杂任务助手
02:14

Project Mariner是Google探索人机交互未来的实验性agent产品，专注于提升浏览器内复杂任务的处理能力。
依托Gemini 2.0的先进推理能力，它能够全面理解和分析浏览器屏幕上的各类信息，包括像素数据、文本内容、代码片段、图片素材和表单元素等，并通过一个实验性的 Chrome 扩展来帮助用户完成任务。
在衡量agent完成真实网页任务能力的WebVoyager基准测试中，Mariner作为单一agent系统取得了83.5%的领先成绩。
不过，该项目在精确度和响应速度方面仍有提升空间。为确保使用安全，Mariner的操作权限被严格限制，对于在线购物等敏感操作必须经过用户确认，以此在安全性和效率间取得平衡。
Jules：为开发者设计的 AI 编程助手
Jules 是一款面向开发者的 AI 驱动代码agent，直接集成到 GitHub 工作流中。得益于 Gemini 2.0 的改进，Jules 可以在开发者的指导和监督下处理问题、制定计划并执行代码任务。这一项目旨在探索 AI agent如何在开发者社区中增强生产力，并为未来跨领域的 AI 应用铺平道路。
游戏agent：打通虚拟与现实边界
02:25

Google还分享了一些原型的隐藏彩蛋。
例如在游戏领域， Gemini 2.0支持的智能agent展示了其在虚拟环境中的强大适应性。不仅能实时分析和推理屏幕动作，还能为玩家提供战略建议。
此前DeepMind推出的Genie 2能从单张图像生成无限可玩的3D游戏世界，而与Supercell等开发商合作的游戏agent则在策略和模拟游戏中展示了出色的规则理解和问题解决能力。结合Google搜索功能，这些agent还能为玩家提供丰富的游戏知识支持。
Gemini 2.0的空间智能潜力
03:09

此外，Gemini 2.0在1.5版本的基础上，将空间理解能力提升到了新的高度。通过AI Studio推出的全新工具集，开发者可以更便捷地探索融合多模态推理的空间智能应用，这不仅体现在虚拟场景中，更可以延伸至机器人等物理世界应用领域。
核心能力提升包括：
• 快速空间分析：能以超低延迟识别和分析图像中物体的空间位置关系
• 智能物体识别：支持图内搜索和匹配，即便是隐藏或模糊的细节也能准确找出
• 多语言空间标注：结合空间信息实现智能多语言标注和翻译
• 空间逻辑理解：掌握物体之间的空间关联，比如实物和对应的影子
• 3D空间重建：首次将2D照片转换为可交互的3D俯视图
在以上演示中，Gemini 2.0展现了多个令人印象深刻的应用场景：从识别折纸动物及其投影，到匹配特定图案的袜子，再到提供物品的双语标注，以及分析现实场景中的问题解决方案。尤其是新引入的3D空间理解功能，虽仍处于早期阶段，却已展现出将平面图像转化为立体可交互场景的潜力，为开发者开启了更广阔的应用想象空间。
与OpenAI今天小打小闹的发布会相比，Google带来的Gemini 2.0不仅支棱起来，而且是凭实力稳稳赢了一局。
Pichai表示，目前已有数百万开发者在使用Gemini构建项目，而Google自身也正借助Gemini重塑旗下七大核心产品，用户群体高达20亿。
此次Gemini 2.0的推出标志着AI正从单纯的信息理解向实际任务执行转变，朝着"通用助手"的目标迈进。坐拥第六代TPU和新发布的量子计算机Willow，Google更像是扮演推动算力极限、实现生产力跃升、引领AGI发展的那个关键角色。
点个“在看”，再走吧
