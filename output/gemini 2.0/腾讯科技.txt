url: /link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS5FLi4EgWb-aspm5LYmOOC_IVPsd-072FlqXa8Fplpd9MvR0xFjGWmhAQDz9cLqjjggMLaohKViPK3ztDITgbaOdLBDpSkS5GqW2qWWA9V249JcIwPUqK1FnO-TBZaqO61OmJu-0xQNw55MevpOc9WU3qE-RC2oKK3_yf8x0jREa5BxG3QIhAQ8MQj8HRn1NWa6bf2bRFjbrJKHKDeN7tSJflztgI7RZ1g..&type=2&query=gemini 2.0&token=DF6742D9295FAB615B5A7250F5C0B85C5C9C6552675A7FDE
title: 谷歌发布新一代大模型
time: 4小时前
abstract: AI未来指北特约作者 郝博阳编辑 郑可君丨划重点① 谷歌发布了新一代大模型
user_id: 腾讯科技
content: AI未来指北特约作者 郝博阳
编辑 郑可君
丨划重点
① 谷歌发布了新一代大模型Gemini 2.0，速度翻倍，能力更强，支持原生图像生成和音频输出的多模态输出。
② 谷歌推出新的多模态实时API，支持实时音频、视频流输入和多个组合工具的使用。此外，还展示了三个智能体研究原型：Project Astra、Project Mariner和Jules。
③ 谷歌Gemini 2.0的发布是对固有业务的防御，以期在更低成本下实现更强大的能力所带来的投资回报率提升。

谷歌用一次发布，干了比OpenAI 五天都多的事儿。

12月12日凌晨，就在OpenAI轰轰烈烈的“12天连续发布”进行到第五天时，谷歌发布了他们的重磅更新—— Gemini 2.0 Flash。

它的速度翻倍，能力更强，且支持原生图像生成和音频输出的多模态输出，以及原生使用 Google 搜索和地图等工具。

这些更新，让谷歌带来的远不止是一个升级版的语言模型，而是一个满足了智能体基本需求的统一底层模型。

谷歌CEO桑达尔·皮查伊在公开信中表示：“如果说Gemini 1.0是关于整理和理解信息，那么Gemini 2.0就是要让这些信息真正变得有用。”


“过去一年，我们一直在投资开发更具主动性的模型，”皮查伊对此解释说，“这意味着它们可以更好地理解周围的世界，提前思考多个步骤，并在你的监督下采取行动。”

这意味着，AI不再只是被动地回答问题，而是能够理解用户的需求，提前思考，并在用户监督下采取行动。想象一个既能帮你规划旅行，又能实际帮你订票的助手，这就是谷歌对未来AI的愿景。

这一愿景，OpenAI提过、微软提过，他们也都推出了自己的理念和渐进性的产品。但真正的完整的系统级 Copilot 和智能体应用，还都在一步步落地之中。

但谷歌这回直接把一整锅都端上桌来了。包括那些OpenAI和微软没展示出来的，它都带来了。

从Gemini 2.0能力结构的提升，到谷歌对Project Astra、Project Mariner和Jules三个智能体研究原型的展示，都标志着谷歌AI已经初步做到了向“主动代理”时代的转变。它意味着AI将从被动的信息处理工具，转变为能够主动思考和行动的智能助手。

就算不说超过竞争对手，随着Gemini 2.0的推出，谷歌也重新回到了产品、模型、智能体、系统这所有领域的一线领先者位置。

谷歌，王者归来。

Gemini 2.0 Flash：村里的新霸主
Gemini Flash 2.0带来了很多眼前一亮的提升，而这些提升最终都可以落地到对智能体的支持上。

技术上的进步首先体现在速度和性能的突破性提升。Gemini 2.0的Flash版本实现了速度翻倍的同时，性能还超越了参数量级更大的1.5 Pro模型。

虽然没有提供和其他主流模型的数据直接对比。但前几天刷屏的竞技场新王Gemini-Exp-1121正是Gemini Flash 2.0。

在这个榜单中我们可以看到，它超越了ChatGPT-4o和o1 Preview，登上了第一。这足见其模型的实力。
而且Flash，是Gemini 模型序列中，除了专为端侧开发的Nano模型外，参数最小的模型。

正如谷歌DeepMind的CTO科雷·卡武克奥卢所说：“如果把我们一年前的位置和现在相比，今天发布的Flash模型比我们一年前的任何模型都要强大得多，而且成本只是其一小部分。”

最小赢过了竞争对手最大、最先进的模型，这让人甚至都很难想象 Gemini 2.0 Ultra 会强到什么地步。

借由模型性能的提升，Gemini能够更好地理解复杂指令、进行长期规划，并具备更强的组合函数调用能力。

这是Gemini强大规划能力的基础。

但更引人注目的是模型的多模态能力。Gemini 2.0不仅能理解文本、图像、视频、音频和代码，还能原生生成图像和多语言音频。

这意味着它可以像人类一样自然地在不同形式的信息之间转换。

在Gemini 1.0时，谷歌已经实现了多模态大系统模型的训练，但生成这一侧他们还是没能突破。现在它做到了。

这是其它所有领先模型都做不到的事，ChatGPT的图片生成还要依靠DALLE，语音生成也是单独的模块。

虽然Gemini 1.0刚推出的时候，大家都认为大一统模型会是未来，但到今天，GPT-4o可能也还没用这种方式训练。

这是Gemini感知能力的基础。

长上下文理解也一直是Gemini的长项，虽然在官方文档中仅仅提及了“更长的上下文”，但鉴于Gemini 1.5 Pro 已经支持 200 万token的海量上下文窗口， Gemini 2不会比这更低。

这是Gemini记忆能力的基础。

此外，Gemini 2.0还能原生调用Google搜索、执行代码以及使用第三方用户定义的功能。

这是Gemini工具使用能力的基础。

让我们回顾前OpenAI研究副总裁翁荔分析的智能体的几大基础能力。记忆、工具使用和规划能力，都在Gemini 2.0中得到了大幅的提升。


而感知，也是传统智能体的核心需求之一，它决定了智能体的应用范围。

谷歌产品经理图尔西·多希在新闻发布会上就表示：“这些新能力使得构建能够思考、记忆、规划，甚至代表你采取行动的代理成为可能。”

从今天开始，全球Gemini用户就可以在桌面和移动网页版中选择使用2.0 Flash实验版，移动应用版本也将很快推出。

谷歌计划在明年初将Gemini 2.0扩展到更多产品中。

对开发者而言，谷歌推出了新的多模态实时API，支持实时音频、视频流输入和多个组合工具的使用。这些功能将从本周开始通过谷歌AI工作室和Vertex AI向开发者开放，而完整版本将于明年1月推出。

接着Gemini-Exp-1121的火热，Gemini 2.0 Flash在正式发布前就已经获得了用户用脚投的票了。

根据API团队产品经理Logan Kilpatrick的数据，“Flash使用量的增长超过900%，这是令人难以置信的。

在过去几个月里，我们推出了六个实验性模型，现在已有数百万开发者在使用Gemini。”

因此，Gemini 2.0的发布确如皮查伊所说，这标志着谷歌AI发展进入了新阶段。

但谷歌并没有止步于此。

让智能体渗入谷歌的每条血脉

如果说Gemini 2.0的技术突破令人印象深刻，那么把它结合进具体的应用场景会诞生什么呢？

答案是：谷歌版的智能体全家桶！

谷歌通过三个研究原型展示了这一技术的潜力：Project Astra、Project Mariner和Jules，每一个都展现了智能体会如何改变我们与数字世界的互动方式。

Project Astra：目前看起来最惊艳的系统级智能体

Project Astra是谷歌最早在今年5月 I/O大会上展示的AI助手，刚发布时看起来并不太惊艳。但现在搭载Gemini 2.0后获得了显著提升。

在演示中，你可以把它当成谷歌版的Apple Intelligence或者Windows Copilot，它的定位是一个系统级的智能体助手。

Astra 利用 Gemini 2.0 内置的代理框架，通过文本、语音、图像和视频回答问题并执行任务，在需要时调用现有的 Google 应用，如搜索、地图和 Lens。

Astra 产品经理 Bibo Xu 表示：“它正在整合当今一些最强大的信息检索系统。”

这使其在日常生活中的实用性大大提高。

在记忆能力方面，Project Astra也有重要突破。系统现在拥有长达10分钟的会话记忆，并能记住过去的对话历史，甚至是多模态的历史，比如在演示中，它甚至能记住你的门锁密码。这让它能提供更加个性化的服务。

以下视频来源于
UnboxTherapy
04:31

通过新的流式处理功能和原生音频理解能力，Astra能以接近人类对话的延迟速度理解语言，也支持多语言。

根据《连线》杂志和彭博社的报道，在谷歌伦敦总部的“家庭图书馆”场景中，这些能力得到了生动展示。Project Astra能够自如地与参观者交谈，解读挪威画家爱德华·蒙克的《呐喊》所反映的焦虑情绪，并探讨这幅作品如何捕捉了那个时代的普遍偏执感。

在布置成酒吧的房间里，它能快速分析视野中的葡萄酒瓶，提供地理信息、口感特征，并从网上搜索价格信息。当有人快速翻阅书籍时，它能实时阅读内容，甚至将西班牙诗歌即时翻译成英语。

这和Greg Brockman给《60 Minutes》节目展示的能实时语音对话的ChatGPT-Vision水平相当，但功能似乎更丰富。

但它同时也是个完整的LLMOS系统，可以结合你在设备上的浏览和通过视频看到的内容综合给出你答案。在演示视频里，小哥先给Astra看了朋友喜欢的书单，又让它通过即时视频推荐书店里有的书。

借由对工具的支持，Astra可以随时获取你所在的地点信息，并了解到该地的具体情况和政策。因此在演示中，小哥想骑车进公园，Astra准确识别出了公园，还告诉他这个公园里不许骑车。

这种多模态间丝滑切换和对工具的无碍结合，目前对Copilot还是OpenAI来讲，都尚未实现。这都是Gemini 2.0原生能力带来的强大加持。毫无疑问，这种体验才是我们日常应用中期待看到的。

难怪MIT Technology review的报道不吝赞美的认为Astra 或将成为生成式 AI 的杀手级应用。

而且谷歌的野心并不止于手机。它已经开始扩大其可信测试者计划，包括让一小组用户在原型XR眼镜上测试Project Astra。它正在探索将这项技术扩展到更多形态，包括AR眼镜等可穿戴设备。

Project Mariner：谷歌版的AutoGLM，但更贴心

Project Mariner则是一个插件版的智能体。毕竟谷歌没有电脑系统，插件是它能找到的最大PC系统入口。作为一个实验性的Chrome扩展，它能够理解和分析浏览器屏幕上的所有信息，包括像素、文本、代码、图像和表单。

当你通过Prompt让它完成一系列工作时，比如在演示中的找到四家公司的邮箱。Mariner可以控制Chrome里的一系列自主操作，包括输入信息，打开网页并网络浏览、进一步点击查询等。

Project Mariner只能在活动标签页中输入、滚动或点击，并且在进行购物等敏感操作前需要用户的最终确认。


它的整体能力和Anthropic10月发布的“计算机使用”功能非常类似。国内的智谱近期发布的AutoGLM也是类似的逻辑。

但Mariner的特别之处在于，它可以把每一步计划像思维链一样同步展示出来，你可以随时叫停并修改它的错误步骤。让用户老板感满满。

而且在WebVoyager基准测试中，Project Mariner作为单一智能体设置取得了83.5%的最优成绩，很能打。

虽然目前导航速度还不够快，准确性也有待提高，但谷歌表示这些问题会随着时间快速改善。

Jules：谷歌也有Devin了，应该卖不到500刀/月

针对开发者群体，谷歌推出了实验性的AI智能体Jules。它和Devin、Cursor 0.43一样，作为编码助手能够制定详尽的多步骤计划来解决问题，高效地修改多个文件，甚至准备拉取请求，将修复直接提交回 GitHub。

另外比较特别的是，Jules 还可以以异步方式工作，并与你的 GitHub 工作流程集成，在你专注于实际想要构建的内容时，它负责处理 Bug 修复和其他耗时的任务。真助手，给你做好同步辅助。

这在Cursor和Devin上似乎还未做到，更别提OpenAI 刚发布的Canva了。

除了这些主要应用，谷歌还在游戏领域进行了有趣的尝试。他们正在与Supercell等领先游戏开发商合作，探索AI代理在不同类型游戏中的应用，从《部落冲突》这样的策略游戏到《卡通农场》这样的模拟经营游戏。

这些游戏AI助手不仅能理解游戏规则和挑战，还能通过实时对话提供建议，甚至调用Google搜索来连接网络上丰富的游戏知识。


在系统级AI助手战争打响：微软用Vision划出了一道分水岭一文中，腾讯科技报道了微软Vision，一个他们刚推出的智能语音助手，它能帮你给购物提意见。在宣传视频里，微软曾提到，也许很快，Vision就能陪你打游戏了。

确实够快，一个礼拜之后就实现了。但是是谷歌实现的。

更令人期待的是，谷歌正在探索将Gemini 2.0的空间推理能力应用到机器人领域。虽然还处于早期阶段，但这预示着AI代理在物理环境中提供帮助的潜力。

这三个产品意味着谷歌通过一场发布会，在主流智能体应用方向上全部追平业界顶尖水平，甚至还能做出点新花样。

Gemini 2.0背后的功臣，英伟达的在喉之梗
支撑这些进步的是谷歌在硬件层面的重大投入。新一代TPU芯片Trillium不仅支持了Gemini 2.0的全部训练和推理过程，现在还向客户开放。

在Gemini 2.0背后，是谷歌最新一代AI芯片的强大支撑。第六代TPU（张量处理器）Trillium不仅全程支持了Gemini 2.0的训练和推理，更代表了AI硬件领域的重大突破。

与上一代相比，Trillium在多个关键指标上都实现了显著提升：训练性能提升超过4倍，推理吞吐量提升达3倍，每芯片的峰值计算性能提升4.7倍，同时能耗效率提升67%。更重要的是，谷歌在单个Jupiter网络架构中部署了超过10万片Trillium芯片，创造了前所未有的规模。

这种性能提升直接体现在大型语言模型的训练上。在训练Llama-2-70B等密集型模型时，Trillium比上一代TPU v5e快4倍。对于越来越流行的混合专家模型（MoE），提升更是达到了3.8倍。

在扩展性方面，Trillium展现出惊人的效率。在使用3072个芯片（12个计算单元）进行训练时，可以达到99%的扩展效率；即使扩展到6144个芯片（24个计算单元），仍能保持94%的效率。这种近乎线性的扩展能力，让Gemini 2.0这样的大规模模型训练成为可能。

不仅是性能，Trillium在成本效益上同样表现出色。在训练大型语言模型时，每美元性能比较上一代提升了2.5倍。在图像生成任务中，生成1000张图像的成本比TPU v5e低27%（离线推理）和22%（在线服务）。

这些进步背后是谷歌在基础设施上的深度创新。AI Hypercomputer架构将优化的硬件、开源软件和领先的机器学习框架整合在一起，通过13Pb/s的双向带宽连接超过10万片Trillium芯片，使单个分布式训练任务能够扩展到数十万个加速器的规模。

对英伟达来讲可能不太好的消息是，Trillium也已经面向Google Cloud客户全面开放。

这意味着企业和初创公司都能够使用与谷歌训练Gemini相同的强大、高效且可持续的基础设施。这可能对于很多模型公司来讲都很有吸引力。

AI21 Labs的CTO Barak Lenz在新闻会上就表示：“作为从v4版本就开始使用TPU的长期用户，我们对谷歌云的Trillium的能力印象深刻。在规模、速度和成本效率方面的进步都很显著。”

多快好省，谷歌更新可能带来商业版图的漂移
谷歌Gemini 2.0的发布带来的商业意义在最显见的层面是对固有业务的防御。

正如彭博社报道指出，Alphabet的谷歌一直在努力确保OpenAI等初创公司推出的最新AI工具不会动摇其在搜索和广告领域的主导地位。尽管谷歌目前仍保持着搜索市场的份额，但OpenAI正在将更多搜索功能整合到ChatGPT中，这给行业领导者带来了压力。

目前，谷歌的AI概览功能已经触及10亿用户，但上一代Gemini 1.0驱动的搜索曾犯下“每天吃石头补钙”这种令人瞠目结舌的错误，让谷歌AI搜索在用户层面上很难被信任。

通过将Gemini 2.0的高级推理能力引入搜索，谷歌希望在更复杂的话题、多步骤问题上保持领先优势。

但这只是第一层。

更重要的一层是ROI上的改变。从今年开始，投资者一直都在对谷歌等公司在AI领域的巨额投入回报率表示担忧。现在好了，Gemini 2.0 flash在更低成本下实现了更强大的能力，多快好省，ROI好看多了。而且如果谷歌保持这一优势，在价格战上都可以耗死对手。

然而，这场AI革命的最终目标似乎指向更远大的愿景。如谷歌DeepMind的CEO戴密斯·哈萨比斯所说，他长期以来一直梦想着一个通用数字助手，将其视为通向通用人工智能的垫脚石。这种愿景与OpenAI等竞争对手的目标不谋而合：都在追求能够执行任务的AGI（通用人工智能），并认为这才是真正的价值所在。

DevMind的CTO卡武克奥卢也强调了这一点：“我们想要构建这种技术——真正的价值就在于此。在通往这一目标的道路上，我们试图选择正确的应用，试图选择正确的问题来解决。”

通过这次更新，谷歌重新回到了智能体的牌桌上，甚至还比别人坐的近了一点。

就在2024年，谷歌就推出了笔记产品NotebookLM，教育AI产品Learn About 两款大热的应用，产品的底子可以说相当厚实。现在再搭配上更好的基础模型，爆款应用还会远吗？

如果2025年是智能体和AI应用的爆发年，那这最大一块蛋糕，现在的谷歌有的分。





推荐阅读
