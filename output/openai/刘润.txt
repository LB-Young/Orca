url: /link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS5FLi4EgWb-a5N4o9B834rDSJwwyhsRcI1qXa8Fplpd9CAjeKflnWVAcSoc9GjPI_i_42XSNLv2atfJu0YYHSMVvmfoTAqtrKAPk_WojoOvIMCplsN6ksrBak_3sgvp7U6-X4ldHenaScbLuwb5RC-juO6BQALIYEBfozOFw7iwBubdAzrL0JXLMcudqNSNyPZCXwW9dOKc7SmfkG9FYESUO8fIRwtipOg..&type=2&query=openai&token=D756F037E28C78AA8F96B86BE99BBA1090D997BC67595F78
title: 突然上线的Sora,到底意味着
time: 9小时前
abstract: 发布会.今年2月,Sora首次发布的时候,我写了一篇文章,和你做了一点简单的介绍.这一次,鸽了快一年的,
user_id: 刘润
content: 刘润
将在12月13日 19:00 直播
预约
刘润东南亚观后感：外面的世界，正在发生什么 | 问道全球

12月10日。凌晨2点。有人呼声正酣，有人还在加班。
此时，一段20分钟的直播，瞬间让静谧的夜晚沸腾了起来。
什么直播？OpenAI发布会。
今年2月，Sora首次发布的时候，我写了一篇文章，和你做了一点简单的介绍。
这一次，鸽了快一年的，OpenAI的文生视频工具Sora，终于开放注册了。
从测试阶段，到使用阶段。Sora，不再是少数人的小众玩具。
你只需要给一段文字，或者给一张图片，就能直接生成一段20秒的1080p视频。
而且，它和人工智能对话聊天机器人ChatGPT共用一个会员体系。你可以选择充积分单独使用，但如果你开了ChatGPT的会员，也能免费用上Sora。
我给你先看几个视频，感受一下。
00:08
（Sora官网视频）
00:09
（Sora官网视频）
00:09
（Sora官网视频）
怎么样？
人脸上的褶皱、神态，拍摄的角度，都非常有电影感。小狗跨过窗台，那种试探路稳不稳的犹豫，都被考虑到了视频里。工地上许多人走来走去，好几个动线，好几个拍摄角度，也依然丝滑。
但是，不需要摄影师，不需要分镜师，不需要动画师，也不需要导演。
这在过去简直无法想象，但是现在，它逐渐照进了现实。
对生成的视频不满意，也没关系，你可以继续修改。修改的方式也很细致。你想从第几秒开始接着前面重新再生成、你想添加或者删减什么细节要素......
只需要你一句话，就能让它再给你生成好几个版本，直到你满意为止。
所以，昨天发布会结束没多久，官网就被涌来的人给弄瘫痪了。奥特曼只好暂停了注册通道。
是的。相信你的朋友圈，这两天也被这件事刷屏了。但你可能依然疑惑：
Sora到底厉害在哪儿？为什么能让我们如此激动？对于OpenAI，乃至人工智能的整体发展来说，Sora到底意味着什么？
有没有人可以用我能听明白的方式，跟我讲讲？
于是，我跑去请教了LangGPT的联合创始人甲木老师，也阅读了很多资料。
Sora测试的这10个月，国产文生视频AI软件也如雨后春笋一般冒出。先跑出来的可灵，紧跟其后的即梦、海螺、vidu，还有开源的混元和智谱，都在做文生视频。不断迭代，不断升级。
所以这一次，比起2月，我有了更多的体感。
其实，在凌晨的发布会上，奥特曼就提到过3个要点。我也把它总结成了3个关键词。理解了这3个关键词，你或许就能理解这件事的来龙去脉了。
共同协作。信息载体。世界模型。
我们一个个来说。
先说，共同协作。
大部分传统视频制作软件，主要充当着“素材工具”、“制作工具”。虽然有了工具，但你可能依然需要许多角色的人，大家一起分工协作，一起使用这些工具，才能最终产出视频。
但如果，这个“许多角色的人”，就是AI呢？
效率，会疯狂提升。
如果AI能帮你联网搜索，给你分点罗列，它就能帮你完成“素材搜集”。如果AI能直接给你成品，你拿着成品，你的工作就从“从零创作”变成了“修改草稿”。
这就是协作。你和它一起，直接对结果负责。
而这回，AI连“修改”都帮你干了。这下，你可能连视频制作的技术都不需要一一掌握了。
比如，remix，重新混合。
你输入一句话，Sora给你生成了一个5秒的视频。你觉得背景很好，但是想把视频里的房子，换成中世纪风格的。你就可以继续在下面打字：请把图中的房子换成中世纪风格。然后点击再次生成，就能局部修改视频。
01:09
（OpenAI Sora Tutorials OpenAI官方示例教程）
比如，re-cut，重新剪辑。
你觉得前2秒很好，但是后3秒很荒唐。你可以从第2秒剪开，让Sora基于前面的2秒，重新再给你混合生成后面的视频。一句话的事。
01:12
（OpenAI Sora Tutorials OpenAI官方示例教程）
比如，blend，混合。
你生成了两个视频，一个蝴蝶振翅，一个花朵盛开。你想让这两个视频丝滑连接起来，就可以用blend功能，一键衔接。
01:34
（OpenAI Sora Tutorials OpenAI官方示例教程）
比如，loop，无限循环。
一直奔跑的羊群、不断翻涌的浪花，就可以用loop来生成。
01:15
（OpenAI Sora Tutorials OpenAI官方示例教程）
还有一个特别炫酷的，storyboard，故事板功能。
你在板上输入描述文字作为提示词，就能生成一块故事板。这一块故事板，就对应一个生成的视频。你可以在视频的时间轴上放置故事板。你放在哪一秒，就从哪一秒开始演绎你编辑的故事视频。你还可以在故事板上，上传一张图。基于你的图，会生成第二块故事板。第二块故事板上，根据你的图，Sora会根据理解自动写成一段文字。
接着，你就可以通过继续修改文字，不断生成新视频。
过去，是你有了灵感再去做视频。从你的头脑里的“灵光一闪”，落实到视频成品，要经过漫长的制作周期。你得先把“灵光”变成更具体的信息，拆解成一步又一步，然后去拍摄、剪辑、调色，才有成品。
而现在，根据你模糊的需求，就能生成视频。这让灵感从你脑子里走向现实的时间，大大缩短了。
一个个成品，直接呈现在你面前。甚至，能反哺你的灵感。
生成的视频，有时甚至比你还要更懂你的想法。因为它是快速的，具体的。
现在，你就能理解，为什么Sora作为一个视频制作工具，它并不是铺满了图层、色彩、聚焦等等复杂菜单。而是，简洁无比的4个选择。你能快速进行基础设置。
1）画面比例。横屏、竖屏或者正方形。2）分辨率。480p、720p还是1080p。3）时长。5s、10s、15s还是20s。4）一次生成几个视频。用来对比选择。
这大大降低了视频制作的使用门槛。
它是你的半个同事，能“试着理解”你说的话。
今天的文生视频AI软件，已经不仅仅是“人在使用工具”，而是“人和AI在协作”。
可是，它们为什么“突然”就能“理解”了呢？
这就要说到第二个关键词，信息载体。
现在，你想做一个产品宣传视频。你可能会打开一个白板，开始构思脚本。如果你有设计伙伴，你可能会把你的需求告诉他，让他帮你一起设计。设计完后，再和做视频的伙伴协作，最后才能产出一个视频。
但是，这一切想要顺利，都得建立在，你每次清楚知道自己需要什么的情况下。
你跟设计师讲，“我想要一个漂亮的视频，穿搭要对比鲜明”。然后等啊等，等他把成品给你，你却发现和你的想法完全不同。你觉得，鲜绿色和亮红色放一起怎么能算“漂亮”呢？设计师却说，这是这个季节很流行的搭配啊，你不是说要“对比鲜明”吗？
反反复复，好不容易敲定了设计，你又去等视频伙伴。再来一轮修改循环。
当最后的视频出来，依然不是你想要的效果。
然而，已经来不及修改了。你很难受，你的设计伙伴和视频伙伴也都很委屈。
但如果，你根据模模糊糊的想法，先生成一系列的视频，再选一个符合你想象的成品小样拿去给视频伙伴看呢？
沟通成本，就大大减少了。
因为视频能够传递的信息，比文字更丰富、更直观。
你拿视频给同事，同事可以更精准地“学习”到你的想法。那，如果你不断拿视频投喂AI呢？AI是不是也能够，更精准地“学习”现实世界？
这就要靠第三个关键词，世界模型。
2月Sora出来的时候，有三个亮点：一次性生成60s高清视频、多角度镜头无缝连接，以及，世界模型。而到了12月，三个亮点都还在，但是生成视频的长度，反而从最多60s，变成了最多20s。
为什么看上去，反而“倒退”了？解释这种“倒退”的，是Sora的后缀，Turbo，“加速”的意思。
虽然一次生成的视频时间短了，但是生成的速度，变快了。
一方面，是因为多角度无缝衔接，细分成了前面写到的Remix、Blend、Loop、Storyboard等更细致的修改功能。另一方面，是因为世界模型。
什么是世界模型？
你可以先简单想象一下：计算机所在的世界，和我们所生活的世界，是两个不同的世界。而世界模型，就是让计算机从它的窗口盯着我们的世界，使劲地看，使劲地学。
而你要做的，就是不断给它投喂营养，让它不断记忆，然后不断预测。
ChatGPT的诞生，验证了这样的“养育”方式，在文字方面，是可行的。
投喂了很多很多文字资料后，你对计算机输入“我”，它就会生成下一个字，可能是“我要”，可能是“我想”，可能是“我是”。
它会根据你的描述，不断迭代怎么预测下一个字，更符合你想要的样子。
而Sora的诞生，则是再次验证了“养育”方式的可行性。或者说，对“真实世界”的学习能力的可行性。
所以，OpenAI突然上线的Sora，为什么能让我们如此激动？
不仅仅是因为它能生成更像样的视频了。更是因为，它更懂这个世界了。
原来当你不断投喂营养，计算机这个小孩，真的可以开始“长大成人”，开始“理解”你，理解这个世界，能处理更复杂的问题了。
你不断给它真实世界的信息，它就开始有“智能”了。
文字，是信息，但是有些模糊。图片，是信息，似乎比文字更好懂一点。视频，也是信息，而且是无比丰富的信息。
它最接近真实世界。因为我们在世界里，都是“会动”的。
计算机你看，那个人类吃汉堡的时候，一口咬下去，剩下的汉堡不是整块的了。看到这段的时候，计算机你先记下来。下一次，你又看到另一个人类吃包子，他张开嘴，咬包子的时候，你试试预测一下，会是什么场景？
“包子穿嘴而过。”错了错了，你再想想？“牙齿碰到的地方会下沉。”对了对了，很接近了，然后呢？“接着会出现一圈齿痕，而咬掉的部分包子，会在嘴里消失不见。”
投喂，再投喂。记忆，再记忆。然后，预测，再预测。
（Sora制作完视频，可以分享到社区）
最终，越来越“逼真”，越来越“智能”。
当然，这类文生视频、图生视频的AI工具，今天还有很多很多的瑕疵。
比如金毛跳到半空屁股变成了头，头变成了屁股。比如偶尔还会出现人物肢体变形、物体突然消失。又比如，因为成本太高，一次生成的视频时间在缩短。
但是GPT的出现，以及Sora的出现，都在一次次验证计算机能够按照人类的学习规律进行学习：先记忆，后预测。
“记忆”越是多，“预测”，就越是有机会更准确。
这也是为什么，未来，来得越来越快了。
GPT-1在2018年发布，用了5年时间，迭代到GPT-3.5才亮相，被众人所知。而从GPT-3.5亮相，到Sora春节第一次发布，只用了1年多。再到现在的Sora Turbo开展公众注册，则是10个月。而且，按照奥特曼的说法，这还只是视频版GPT-1，还是一个初级版本。
那么，我们呢？在“未来”面前，我们该怎么办？
这次的发布会，我想奥特曼真正想表达的，是呼吁你我去和AI协作。然后，尽早找到自己的正确节奏。
开发大模型很昂贵。迭代大模型需要很复杂的技术。但是，普普通通的你和我，都会有和AI相处的节奏。
细分，是机会。比如专门做数字人口型。组合，是机会。比如制作AI创意视频。
关键的是，你的节奏是什么？
OpenAI官方的教学视频里面，有一句让我印象特别深刻。
Find the right pace for your story.（为你的故事找到正确的节奏。）
正确的节奏下，AI从来都不是在替代，而是在共同协作，是在弥补信息不对称，是在让新旧世界重构。
祝你，找到你的节奏。
共勉。

P.S.
最后的最后，我想再次感谢甲木老师的帮助。
如果，你也有一些想向甲木老师请教的问题，那么，欢迎你加入“刘润·进化岛”，和我们一起学习。
在“刘润·进化岛”上，你可以直接向我们提问，收听我的商业日课；可以认识2.56万名创业者朋友，提升自己的商业认知；可以回看商业访谈，听大咖讲书，收获更多的思路和视角……
正好最近，“刘润·进化岛”也在举办双12年终盛典。更多详情，欢迎你点击下方图片进行了解。
我在岛上，等你。
*个人观点，仅供参考。
*头图来自于sora官网
参考资料 
1、《Sora终于来了！自带剪辑工具，145块就能玩｜OpenAI直播第三天》，腾讯科技 
2、《Sora开服被挤爆！支持中文/编剧模式/作品分享，145块就能玩》，量子位
3、《刚刚，OpenAI Sora正式炸裂登场，网页挤爆了！》，机器之心
4、《Sora火爆上线系统秒瘫，奥特曼直播第三更网友震翻！20秒1080p拍大片再近AGI》
主笔 / 木言声 编辑 / 二蔓  版面 / 黄静
这是刘润公众号的第2454篇原创文章


推荐阅读：
《真正的管理高手，会回答，更会提问》
《做一个运气很好的人》
《营销是个大力士，但不是神》
品牌推广 | 培训合作 | 商业咨询 | 润米商城 | 转载开白
请在公众号后台回复  合作 
