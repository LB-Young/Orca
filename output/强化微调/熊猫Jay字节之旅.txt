url: /link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgSxsgUKqvZowFotenrcOYzEHRPlDO6foImFqXa8Fplpd9mQK_whlmUSfKaN0K24LXyxPyLUgwMPXuA0SsWeaNkZaMD3hxhmQfM-JgFK2J6wfk-4mO0_DBxjDLggEALiexrhSCaKtIgwdAFneIp8uPhyIV3lRBxGNU3C8KC6kEN_VOhKBuoWUabC41HZcBOSATGFHiQieF3b26BMpF1fHZR8lQL0Hr9Gyd3Q..&type=2&query=%E5%BC%BA%E5%8C%96%E5%BE%AE%E8%B0%83&token=B31484EE3EEFB6CB17113FBF561F068F184B10836753EB4A
title: OpenAI 
time: 6小时前
abstract: OpenAI 新货来啦 --- “RFT(
user_id: 熊猫Jay字节之旅
content: OpenAI 新货来啦 --- “RFT(强化微调)”。
微调技术已经见怪不怪了，为什么这次的强化微调，能让奥特曼称之为 2024 最大的惊喜？
先别急，让我们从头说起。
过去的微调技术，就像是给 AI 补习功课。
你得准备一大堆特定领域的"教材"（数据），才能把一个"全能型选手"训练成某个领域的"专家"。比如：
想要一个精通金融的 GPT 4？需要海量金融数据。想要一个擅长写小说的 GPT 4？得准备大量优质小说。想要一个通晓国学的 GPT 4？那就得来一打经典著作。
但这一次，OpenAI 带来的强化微调却不太一样。
因为它是基于 o1 作为底座开发的新技术，而 o1 可不是普通的大模型...
为什么这个看似普通的技术升级，却让奥特曼如此兴奋？
关键在于 o1 的特别之处：
传统模型：直接模式匹配 → 输出答案。o1：分析问题 → 推理思考 → 形成论证 → 得出结论
这就是为什么 o1 给的答案更有深度，逻辑性更强。
但也正因如此，针对 o1 这样的高级模型，普通微调已经无法满足要求了。
不过在奥特曼发的推特里，我捕捉到了一个特别的关键词：极少。这个词背后，可能藏着一个巨大的突破......
如果 OpenAI 这次不再忽悠人， 能达到用极少特定领域的数据就能训练成一个专家，那很多事情将变得非常简单。
搞自媒体的朋友们， 可以拿 10、20 篇，自己写的比较好的文章， 训练成一个很好的辅助你写作的大模型。
做律师的朋友们， 也可以提供给他常用的法条和案例， 训练成一个法律助手， 帮自己快速分析案件。
但是， 无论是文章、还是法律和案例， 可多可少， 施展空间比较大。
对于工业、食品、化工等等领域的企业来说，可就没那么容易了。
大家都知道配方这个概念 --- 也就是一款产品的核心。
配方决定着一个公司的命运，它的价值就拿可口可乐来举例子:
2023 年的数据，可口可乐公司的市值高达2600 亿美元，全球每年销售额超过458。3 亿美元。
其中，核心产品——“可口可乐”饮料就占了约40% 的销售额。
而这一切的背后，就是那个保密超过 130 年的配方。
一个公司， 无论是做什么， 做食品、做化工的， 配方一旦丢了， 公司可能就没了。
所以配方这样的数据， 不存在公开， 除非是犯罪。
企业内部的配方数据往往非常稀少，很难多到可以成为微调大模型的样本。
我们来看个真实的需求:
一家做电缆材料的企业， 客户要求他们电缆线需要铺设在海底、赤道、极地 等等环境下， 那么对于抗紫外线、抗老化等等参数都会有不同的要求。

怎么样只需要给大模型几个参数， 他就可以根据企业内部的配方数据推荐出一套符合要求， 但成本最优的配方呢。
这样情况下， 企业内部过去的配方数据是非常少的， 可能也只有几十笔。
常规做法就是消耗巨大的实验成本， 不停消耗人力、物力来找到最佳配方。
一句话总结这个痛点：数据少, 但要求高；成本贵，所以必须做。
如果 RFT ， 或者未来的某一项技术能够更容易地解决，哪怕是接近 ，那这个商业价值不可估量。
OpenAI RFT 申请地址: https://openai.com/form/rft-research-program/
申请通过后，会收到类似这样的通知:
奥特曼， 别再让它遥遥无期了~
这次，我们都不想只是填个表单。
over ~
我是熊猫 Jay 🐼，希望分享能给你带来一些帮助。
如果觉得不错，随手点个赞、在看、转发三连吧。
如果想第一时间收到推送，也可以给我个星标 ⭐
谢谢你看我的文章 ~
